<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <script src="page_files/head.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="./favicon.ico">
    <meta name="description" content="Domain and Content Adaptive Convolution for Domain Generalization in Medical Image Segmentation">
    <meta name="keywords" content="Domain Generalization,Medical Image Segmentation,Dynamic Network">

    <title>DCAC</title>
    <link rel="stylesheet" href="page_files/font.css">
    <link rel="stylesheet" href="page_files/main.css">


    <style type="text/css">
        .layered-paper-big {
            /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
            box-shadow: 0px 0px 1px 1px rgba(0, 0, 0, 0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0, 0, 0, 0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0, 0, 0, 0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0, 0, 0, 0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0, 0, 0, 0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0, 0, 0, 0.35);
            /* The fifth layer shadow */
            margin-left: 10px;
            margin-right: 45px;
        }
    </style>

</head>

<body data-gr-c-s-loaded="true" data-new-gr-c-s-check-loaded="14.1028.0" data-gr-ext-installed="">

    <div class="outercontainer">
        <div class="container">

    <div class="content project_title">
        <h1>Domain and Content Adaptive Convolution based Multi-Source Domain Generalization for Medical Image Segmentation</h1>
    </div>

    <div class="content project_headline">
        <center>
            <h2>
            <table align="center" width="800px">
                <tbody>
                    <tr>
                        <td align="center" width="100px">
                            <center>
                                <span style="font-size:20px"><a href="https://shishuaihu.github.io/">
                                Shishuai Hu</a></span><br><span style="font-size:15px">Northwestern Polytechnical University</span>
                            </center>
                        </td>
                        <td align="center" width="100px">
                            <center>
                                <span style="font-size:20px"><a href="https://merrical.github.io/">
                                Zehui Liao</a></span><br><span style="font-size:15px">Northwestern Polytechnical University</span>
                            </center>
                        </td>
                        <td align="center" width="100px">
                            <center>
                                <span style="font-size:20px"><a href="https://jianpengz.github.io/">
                                Jiangpeng Zhang</a></span><br><span style="font-size:15px">Northwestern Polytechnical University</span>
                            </center>
                        </td>
                        <td align="center" width="100px">
                            <center>
                                <span style="font-size:20px"><a href="https://teacher.nwpu.edu.cn/yongxia">
                                Yong Xia</a></span><br><span style="font-size:15px">Northwestern Polytechnical University</span>
                            </center>
                        </td>
                    </tr>
                </tbody>
            </table>
            </h2>
        </center>
    </div>

    <div class="content project_headline">
        <center>
            <h2>
                <table align="center" width="800px">
                <tbody>
                    <tr>
                        <td align="center" width="150px">
                            <center>
                                <span style="font-size:18px"></span>
                            </center>
                        </td>
                        <td align="center" width="200px">
                            <center>
                                <span style="font-size:18px">Code <a href="https://github.com/ShishuaiHu/DCAC"> [GitHub]</a></span>
                            </center>
                        </td>
<!--                        <td align="center" width="200px">-->
<!--                            <center>-->
<!--                                <span style="font-size:18px">arXiv<a href="https://arxiv.org/abs/2109.05676"> [Paper]</a></span>-->
<!--                            </center>-->
<!--                        </td>-->
                        <!-- <td align="center" width="200px">
                            <center>
                                <span style="font-size:18px">Poster<a href="https://yassouali.github.io/cct_page/files/poster.pdf"> [pdf]</a></span>
                            </center>
                        </td>
                        <td align="center" width="200px">
                            <center>
                                <span style="font-size:18px">Slides<a href="https://yassouali.github.io/cct_page/files/slides.pdf"> [pdf]</a></span>
                            </center>
                        </td> -->
                        <td align="center" width="150px">
                            <center>
                                <span style="font-size:18px"></span>
                            </center>
                        </td>
                    </tr>
                </tbody>
                </table>
            </h2>
        </center>
    </div>

    		<br> <br>
            <div class="content project_headline">
                <div class="img" style="text-align:center; max-width: 70%;">
                    <img class="img_responsive" src="page_files/overview.png" alt="Overview">
                </div>
                <div class="text">
                    <p>Figure 1: Example of Multi-source Domain Generalization in Medical Image Segmentation.</p>
                </div>
            </div>
            <br>

            <div class="content">
                <div class="text">
                    <h2>Abstract</h2>
                    <p>
The domain gap caused mainly by variable medical image quality renders a major obstacle on the path between training a segmentation model in the lab and applying the trained model to unseen clinical data. To address this issue, domain generalization methods have been proposed, which however usually use static convolutions and are less flexible.
In this paper, we propose a multi-source domain generalization model, namely domain and content adaptive convolution (DCAC), for medical image segmentation.
Specifically, we design the domain adaptive convolution (DAC) module and content adaptive convolution (CAC) module and incorporate both into an encoder-decoder backbone.
In the DAC module, a dynamic convolutional head is conditioned on the predicted domain code of the input to make our model adapt to the unseen target domain.
In the CAC module, a dynamic convolutional head is conditioned on the global image features to make our model adapt to the test image.
We evaluated the DCAC model against the baseline and four state-of-the-art domain generalization methods on the prostate segmentation, COVID-19 lesion segmentation, and optic cup/optic disc segmentation tasks.
Our results indicate that the proposed DCAC model outperforms all competing methods on each segmentation task, and also demonstrate the effectiveness of the DAC and CAC modules.
                    </p>
                </div>
            </div>

            <div class="content">
                <div class="text">
                    <h2>Highlights</h2>
                    <div class="text">
                        <p><b> (1) Multi-scale features based domain relationship modeling.</b> <br>
We use the domain-discriminative information embedded in the encoder feature maps to generate the domain
code of each input image, which establishes the relationship between multiple source domains and the unseen
target domain.</p>
                    </div>

                    <div class="text">
                        <p><b> (2) Domain and Content Adaptive Convolution. </b> <br>
We design the dynamic convolution-based domain adaptive convolution (DAC) module and content adaptive convolution (CAC) module to enable our DCAC model to adapt
not only to the unseen target domain but also to each test
image.</p>
                    </div>

                    <div class="text">
                        <p><b> (3) Competitive results on three benchmarks.</b> <br>
We present extensive experiments, which demonstrate
the effectiveness of our DCAC model against the state-of-the-art in three medical image segmentation benchmarks with different imaging modalities.
                        </p>
                    </div>

                </div>
            </div>

            <div class="content">
                <div class="text" style="width: 350px;">
                    <h2>Publication</h2>
                    <ul>
                        <li>
                            <div class="title"><a name="DCAC">Domain and Content Adaptive Convolution for Domain Generalization in Medical Image Segmentation</a></div>
                            <div class="authors">
                                <a href="https://shishuaihu.github.io/">Shishuai Hu</a>,
                                Zehui Liao,
                                <a href="https://jianpengz.github.io/">Jianpeng Zhang</a>,
                                <a href="https://teacher.nwpu.edu.cn/yongxia">Yong Xia</a>
                            </div>
                            <div>
                                <span class="tag"><a href="https://arxiv.org/abs/2109.05676">arXiv</a></span>
                                <span class="tag"><a href="https://github.com/ShishuaiHu/DCAC">Code</a></span>
                            </div>
                        </li>
                    </ul>
                </div>
                <div class="text" style="text-align:left">
                    <table align="center" width="200" px="">
                        <tbody>
                            <tr>
                                <td>
                                    <a href="https://arxiv.org/abs/2109.05676">
                                    <img class="layered-paper-big" style="height:175px" src="page_files/paper_thumb.png"></a>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <div class="content">
                <div class="text">
                    <h2>Method</h2>
                    <p> The proposed DCAC model is an encoder-decoder structure equipped with a domain predictor, a domain-aware controller, a content-aware controller, and a series of domain-adaptive heads and content-adaptive heads.
The workflow of this model consists of four steps.
First, the feature map produced by each encoder layer is aggregated and fed to the domain predictor.
Second, based on the generated domain code, the domain-aware controller predicts the parameters of the domain-adaptive head.
Third, the content-aware controller uses the final output of the encoder as its input to generate the parameters of the content-adaptive head.
Finally, according to the deep supervision strategy, the output of each decoder layer is fed sequentially to a domain-adaptive head and a content-adaptive head, which predict the segmentation result on a pixel-by-pixel basis.
The diagram of our DCAC model is shown in Figure 2.
                    </p>
                </div>
                <div class="img" style="text-align:center">
                    <img class="img_responsive" src="page_files/method.png" alt="Method" style="margin:auto;max-width:100%">
                </div>
                <div class="text">
                    <p>Figure 2: Architecture of the proposed method. The feature map in orange color represents GAP(f_E^N), i.e., the output of the N-th encoder block after global average pooling.
                    </p>
                </div>
            </div>

            <div class="content">
                <div class="text">
                    <h2>Datasets</h2>
                    <p> Three datasets were used for this study.
For prostate segmentation, the dataset contains 116 T2-weighted MRI cases from six domains. We preprocessed the MRI data and only preserved the slices with the prostate region for consistent and objective segmentation evaluation.
For COVID-19 lesion segmentation, the dataset consists of 120 RT-PCR positive CT scans with pixel-level lesion annotations, collected from the first multi-institutional, multi-national expert annotated COVID-19 image database.
For OC/OD segmentation, the dataset contains 789 cases for training and 281 cases for test, which are collected from four public fundus image datasets and have inconsistent statistical characteristics.
The statistics of three datasets were summarized in Table 1.
                    </p>
                </div>
                <div class="img" style="text-align:center">
                    <img class="img_responsive" src="page_files/datasets.png" alt="Datasets" style="margin:auto;max-width:90%">
                </div>
                <div class="text">
                    <p>Table 1: Statistics of three datasets used for this study.</p>
                </div>
                <br>
                <div class="text">
                    <h3>Datasets Download Link</h2>
                    <ul>
                        <li>
                            <p>
                            <a href="https://liuquande.github.io/SAML">Prostate segmentation and dataset details.</a>
                            </p>
                        </li>
                        <li>
                            <p>
                            <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=80969742">COVID-19 lesion segmentation.</a>
                            </p>
                        </li>
                        <li>
                            <p>
                            <a href="https://drive.google.com/file/d/1p33nsWQaiZMAgsruDoJLyatoq5XAH-TH/view?usp=sharing">OC/OD segmentation.</a>
                            </p>
                        </li>
                    </ul>
                </div>
            </div>

            <div class="content">
                <div class="text">
                    <h2>Main Results</h2>
                    <p> We compared the proposed DCAC model with the ‘Intra-domain’ setting (i.e., training and testing on the data from the same domain), ‘DeepAll’ baseline (i.e., training on the data aggregated from all source domains and testing directly on the unseen target domain), and four DG methods, including (1) BigAug: a data-augmentation based method (Zhang et al. 2020), (2) SAML (Liu, Dou, and Heng 2020) and FedDG (Liu et al. 2021a): two meta-learning-based methods, and (3) DoFE: a domain-invariant feature learning approach (Wang et al. 2020).
                    </p>
                </div>
                <div class="img" style="text-align:center">
                    <img class="img_responsive" src="page_files/result1.png" alt="Results" style="margin:auto;max-width:90%">
                </div>
                <div class="img" style="text-align:center">
                    <img class="img_responsive" src="page_files/result2.png" alt="Results" style="margin:auto;max-width:90%">
                </div>
                <div class="img" style="text-align:center">
                    <img class="img_responsive" src="page_files/result3.png" alt="Results" style="margin:auto;max-width:90%">
                </div>
                <div class="text">
                    <p>Figure 3: Quantitative results.
                    </p>
                </div>
                <div class="img" style="text-align:center">
                    <img class="img_responsive" src="page_files/visualization.png" alt="Visualization" style="margin:auto;max-width:90%">
                </div>
                <div class="text">
                    <p>Figure 4: Visualization results.
                    </p>
                </div>
            </div>


            <!-- <div class="content">
                <div class="text">
                    <h3>Acknowledgments</h3>
                    <p>
                    </p>
                </div>
            </div> -->


            <div class="content">
                <div class="text">
                    <h2>Related Publications</h2>
                    <ul>
                        <li>
                            <p>
                            <a href="https://arxiv.org/abs/2010.06208">DoFE: Domain-oriented Feature Embedding for Generalizable Fundus Image Segmentation on Unseen Datasets.</a>
                            Shujun Wang, Lequan Yu, Kang Li, Xin Yang, Chi-Wing Fu, Pheng-Ann Heng. <i>IEEE-TMI 2020</i>
                            </p>
                        </li>
                        <li>
                            <p>
                            <a href="https://arxiv.org/abs/2007.02035">Shape-aware Meta-learning for Generalizing Prostate MRI Segmentation to Unseen Domains.</a>
                            Quande Liu, Qi Dou, Pheng-Ann Heng. <i>MICCAI 2020</i>
                            </p>
                        </li>
                        <li>
                            <p>
                            <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_FedDG_Federated_Domain_Generalization_on_Medical_Image_Segmentation_via_Episodic_CVPR_2021_paper.html">FedDG: Federated Domain Generalization on Medical Image Segmentation via Episodic Learning in Continuous Frequency Space.</a>
                            Quande Liu, Cheng Chen, Jing Qin, Qi Dou, Pheng-Ann Heng.<i>CVPR 2021</i>
                            </p>
                        </li>
                        <li>
                            <p>
                            <a href="http://openaccess.thecvf.com/content/CVPR2021/html/Zhang_DoDNet_Learning_To_Segment_Multi-Organ_and_Tumors_From_Multiple_Partially_CVPR_2021_paper.html">DoDNet: Learning To Segment Multi-Organ and Tumors From Multiple Partially Labeled Datasets.</a>
                            Jianpeng Zhang, Yutong Xie, Yong Xia, Chunhua Shen.<i>CVPR 2021</i>
                            </p>
                        </li>
                      </ul>
                </div>
            </div>

            <div class="content">
                <div class="text">
                    <h2>Citation</h2>
                    If this work is helpful for your research, please consider citing:
                    <pre>
                    <code>
@misc{hu2021domain,
      title={Domain and Content Adaptive Convolution for Domain Generalization in Medical Image Segmentation},
      author={Shishuai Hu and Zehui Liao and Jianpeng Zhang and Yong Xia},
      year={2021},
      eprint={2109.05676},
      archivePrefix={arXiv},
      primaryClass={eess.IV}
}
                    </code>
                    </pre>
                </div>
            </div>


            <div class="content">
                <div class="text">
                    <b>Acknowledgement:</b> This page is based on <a href="https://hobbitlong.github.io/CMC/">this template</a>
                    by <a href="http://people.csail.mit.edu/yonglong/"> Yonglong Tian </a>
                </div>
            </div>

        </div>
    </div>

<div id="footer" align="center">
	<div id="footer-text"></div>
    <div id="clustrmaps-widget" style="width:30%">
		<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=a3BzbzJbzoNt-RDPueJgP5s86N6akFSSOHpoc_JGrrc&cl=ffffff&w=a"></script>
	</div>
</div>

</body>
</html>